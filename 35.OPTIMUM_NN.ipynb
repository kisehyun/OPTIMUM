{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b21b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c17f9",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cadaac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Concrete_Data.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0e352",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "- 80% -> Train\n",
    "- 20% -> Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0578ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b950c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[:nrow * 0.8]\n",
    "test = data.loc[nrow * 0.8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e10c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train.iloc[:, :-1])\n",
    "y_train = np.array(train['Concrete compressive strength(MPa, megapascals) '])\n",
    "\n",
    "X_val = np.array(test.iloc[:, :-1])\n",
    "y_val = np.array(test['Concrete compressive strength(MPa, megapascals) '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f166cf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((825, 8), (206, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0352637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab97646",
   "metadata": {},
   "source": [
    "### Custom Function for searching theta, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "757eb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    mu = np.mean(x, axis = 0)\n",
    "    sig = np.std(x, axis= 0, ddof = 1)\n",
    "    norm = (x - mu)/sig\n",
    "    return norm, mu, sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87488c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_search(X, y, theta):\n",
    "    predictions = X.dot(theta)\n",
    "    errors = np.subtract(predictions, y)\n",
    "    sqrErrors = np.square(errors)\n",
    "    return 1/(2 * l) * errors.T.dot(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0ceb8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, y, theta, learning_rate, iterations):\n",
    "    cost = np.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        prd = X.dot(theta)\n",
    "        error = np.subtract(prd, y)\n",
    "        delta = (learning_rate / l) * X.transpose().dot(error);\n",
    "        theta = theta - delta;\n",
    "        cost[i] = cost_search(X, y, theta)\n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b204f",
   "metadata": {},
   "source": [
    "### Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2342494",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, mu, sig = normalize(X_train)\n",
    "X = np.hstack((np.ones((l, 1)), X))\n",
    "theta = np.zeros(X_train.shape[1] + 1)\n",
    "iterations = 500\n",
    "learning_rate = 0.15\n",
    "theta, cost = gradient(X, y_train, theta, learning_rate, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6b8a6",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b03a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ((X_val - mu) / sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1517c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c64fbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(test_data.shape[0]) :\n",
    "    target = np.hstack((np.ones(1), test_data[n])).dot(theta)\n",
    "    target_values.append(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdfee7",
   "metadata": {},
   "source": [
    "### Evaluation - MAE(Mean Absolute Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d8a4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'Actual' : y_val, 'Prediction' : target_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04cc6fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.752968</td>\n",
       "      <td>18.827615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.093289</td>\n",
       "      <td>32.603310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.393661</td>\n",
       "      <td>35.609625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.511012</td>\n",
       "      <td>48.371938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.987410</td>\n",
       "      <td>50.800604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Prediction\n",
       "0  21.752968   18.827615\n",
       "1  39.093289   32.603310\n",
       "2  24.393661   35.609625\n",
       "3  50.511012   48.371938\n",
       "4  74.987410   50.800604"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b097f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.sum(abs(y_val - target_values)) / len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81b2692a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.927617208915032"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b74b06c",
   "metadata": {},
   "source": [
    "***\n",
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ecdcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b962d3d4",
   "metadata": {},
   "source": [
    "활성화 함수인 Softmax 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fde09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(x) :\n",
    "    if x <= 21 :\n",
    "        return 1\n",
    "    elif 22 <= x < 45 :\n",
    "        return 2\n",
    "    else :\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537056ad",
   "metadata": {},
   "source": [
    "MPa기준으로 그룹핑 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f9fd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_layer_forward(X, W, b):\n",
    "    y = X.dot(W) + b\n",
    "    cache = (X, W, b)\n",
    "    return y, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e50b5b",
   "metadata": {},
   "source": [
    "affine 층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d52eb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf9210",
   "metadata": {},
   "source": [
    "시그모이드 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc36de01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['Concrete compressive strength(MPa, megapascals) '].apply(get_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b27aa04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame()\n",
    "X_val = pd.DataFrame()\n",
    "X_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81af259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3] :\n",
    "    df = data[data.target == i]\n",
    "    tr = df.sample(int(df.shape[0] * 0.7))\n",
    "    val = df.query('index not in @tr.index')\n",
    "    val = val.sample(int(val.shape[0] * (2/3)))\n",
    "    te = df.query('index not in @tr.index and index not in @val.index')\n",
    "    \n",
    "    X_train = pd.concat([X_train, tr], axis = 0, ignore_index = True)\n",
    "    X_val = pd.concat([X_val, val], axis = 0, ignore_index = True)\n",
    "    X_test = pd.concat([X_test, te], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f17820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(X_train.iloc[:, -1] - 1).to_numpy()\n",
    "y_val = pd.get_dummies(X_val.iloc[:, -1] - 1).to_numpy()\n",
    "y_test = pd.get_dummies(X_test.iloc[:, -1] - 1).to_numpy()\n",
    "X_train = X_train.iloc[:, :-2].to_numpy()\n",
    "X_val = X_val.iloc[:, :-2].to_numpy()\n",
    "X_test = X_test.iloc[:, :-2].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34f58b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c445a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73951781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f40b20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_layer_backward(dy, cache):\n",
    "    X, W, b = cache\n",
    "    dX = np.dot(dy, W.T)\n",
    "    dW = np.dot(X.T, dy)\n",
    "    db = np.sum(dy, axis=0)\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16ba79aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(X, Y, W1, b1, W2, b2, learning_rate, verbose=False):\n",
    "    a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "    z1 = sigmoid(a1)\n",
    "    a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "    y_hat = softmax(a2)\n",
    "    Loss = cross_entropy_error(y_hat, Y)\n",
    "  \n",
    "    dy = (y_hat - Y) / X.shape[0]\n",
    "    dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "    da1 = sigmoid_grad(a1) * dz1\n",
    "    dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "    \n",
    "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    \n",
    "    return W1, b1, W2, b2, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc308afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W1, b1, W2, b2, X):\n",
    "    a1 = X.dot(W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    y = softmax(a2)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2974a361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_params(input_size, hidden_size, output_size, weight_init_std=0.1):\n",
    "\n",
    "    W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros(hidden_size)\n",
    "    W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros(output_size)\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e0c2a48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "iters_num = 100000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = X_train.shape[0]\n",
    "batch_size = 32   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "W1, b1, W2, b2 = init_params(8, 32, 3)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = X_train[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "    \n",
    "    W1, b1, W2, b2, Loss = train_step(x_batch, y_batch, W1, b1, W2, b2, learning_rate=0.25, verbose=False)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_pred = np.argmax(predict(W1, b1, W2, b2, X_train), axis = 1)\n",
    "        val_pred = np.argmax(predict(W1, b1, W2, b2, X_val), axis = 1)\n",
    "        test_pred = np.argmax(predict(W1, b1, W2, b2, X_test), axis = 1)\n",
    "\n",
    "tr_r_score = recall_score(np.argmax(y_train, axis = 1), train_pred, average = 'weighted')\n",
    "val_r_score = recall_score(np.argmax(y_val, axis = 1), val_pred, average = 'weighted')\n",
    "te_r_score = recall_score(np.argmax(y_test, axis = 1), test_pred, average = 'weighted')\n",
    "\n",
    "tr_p_score = precision_score(np.argmax(y_train, axis = 1), train_pred, average = 'weighted')\n",
    "val_p_score = precision_score(np.argmax(y_val, axis = 1), val_pred, average = 'weighted')\n",
    "te_p_score = precision_score(np.argmax(y_test, axis = 1), test_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc602e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score\n",
      "Train | 0.5159944367176634\n",
      "Validation | 0.5145631067961165\n",
      "Test | 0.5142857142857142\n",
      "\n",
      "Precision Score\n",
      "Train | 0.26625025872357877\n",
      "Validation | 0.2647751908756716\n",
      "Test | 0.2644897959183673\n"
     ]
    }
   ],
   "source": [
    "print('Recall Score')\n",
    "print(f'Train | {tr_r_score}')\n",
    "print(f'Validation | {val_r_score}')\n",
    "print(f'Test | {te_r_score}')\n",
    "\n",
    "print('\\nPrecision Score')\n",
    "print(f'Train | {tr_p_score}')\n",
    "print(f'Validation | {val_p_score}')\n",
    "print(f'Test | {te_p_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a903b8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f78ea503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "# Use loadmat to load matlab files\n",
    "mat=loadmat(\"ex3data1.mat\")\n",
    "# mat is a dict with key \"X\" for x-values, and key \"y\" for y values\n",
    "X = mat[\"X\"]\n",
    "y = [v[0] for v in mat[\"y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b49cb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbe4e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "264e5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "349a2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 884736743\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11daf7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu (x):\n",
    "    return (x>=0) * x\n",
    "\n",
    "# 양의 입력에 대해 1을, 그렇지 않으면 0을 반환하는 ReLU 기능의 파생 모델을 설정\n",
    "def relu2deriv(output):\n",
    "    return output >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6dc0715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(learning_rate, epochs, hidden_size, n_features, num_labels) :\n",
    "\n",
    "    weights_1 = 0.2 * rng.random((n_features, hidden_size)) - 0.1\n",
    "    weights_2 = 0.2 * rng.random((hidden_size, num_labels)) - 0.1\n",
    "\n",
    "    store_training_loss = []\n",
    "    store_test_loss = []\n",
    "\n",
    "    # 훈련 루프 시작\n",
    "    # 정의된 에포크(반복)의 수에 대한 학습 실험을 실행\n",
    "    for j in range(epochs):\n",
    "\n",
    "        #################\n",
    "        #    훈련 단계   #\n",
    "        #################\n",
    "\n",
    "\n",
    "        # 훈련셋의 모든 데이터에 대한 순전파와 역전파를 수행하고 그에 따른 가중치 조정\n",
    "        for i in range(len(X_train)):\n",
    "            layer_0 = X_train[i]\n",
    "            layer_1 = np.dot(layer_0, weights_1)\n",
    "            layer_1 = relu(layer_1)\n",
    "            dropout_mask = rng.integers(low=0, high=2, size=layer_1.shape)\n",
    "            layer_1 *= dropout_mask * 2\n",
    "            layer_2 = np.dot(layer_1, weights_2)\n",
    "\n",
    "            # 역전파:\n",
    "\n",
    "            layer_2_delta = (y_train[i] - layer_2)\n",
    "            layer_1_delta = np.dot(weights_2, layer_2_delta) * relu2deriv(layer_1)\n",
    "            layer_1_delta *= dropout_mask\n",
    "            weights_1 += learning_rate * np.outer(layer_0, layer_1_delta)\n",
    "            weights_2 += learning_rate * np.outer(layer_1, layer_2_delta)\n",
    "\n",
    "\n",
    "        ###################\n",
    "        #    측정 단계     #\n",
    "        ###################\n",
    "\n",
    "        train_pred = relu(X_train @ weights_1) @ weights_2\n",
    "        test_pred = relu(X_test @ weights_1) @ weights_2\n",
    "\n",
    "\n",
    "        # 세트별 성능 측정\n",
    "        tr_recall = round(recall_score(np.argmax(y_train, axis = 1), np.argmax(train_pred, axis = 1), average = 'weighted'), 3)\n",
    "        te_recall = round(recall_score(np.argmax(y_test, axis = 1), np.argmax(test_pred, axis = 1), average = 'weighted'), 3)\n",
    "\n",
    "        tr_precision = round(precision_score(np.argmax(y_train, axis = 1), np.argmax(train_pred, axis = 1), average = 'weighted'), 3)\n",
    "        te_precision = round(precision_score(np.argmax(y_test, axis = 1), np.argmax(test_pred, axis = 1), average = 'weighted'), 3)\n",
    "\n",
    "        tr_f1 = round(f1_score(np.argmax(y_train, axis = 1), np.argmax(train_pred, axis = 1), average = 'weighted'), 3)\n",
    "        te_f1 = round(f1_score(np.argmax(y_test, axis = 1), np.argmax(test_pred, axis = 1), average = 'weighted'), 3)\n",
    "\n",
    "\n",
    "        # 각 에포크에서 성능 출력\n",
    "        print(f'########## Epoch {j + 1} #########')\n",
    "        print(f'Summary of Train Set')\n",
    "        print(f'Recall : {tr_recall} / Precision : {tr_precision} / F1 : {tr_f1}')\n",
    "        print(f'\\nSummary of Test Set')\n",
    "        print(f'Recall : {te_recall} / Precision : {te_precision} / F1 : {te_f1}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96834961",
   "metadata": {},
   "source": [
    "함수 구성방식(학습률, 에포크, 은닉층 노드수, 인풋데이터 컬럼 수, 레이블 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a89887c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Epoch 1 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.315 / Precision : 0.213 / F1 : 0.229\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.314 / Precision : 0.209 / F1 : 0.231\n",
      "\n",
      "########## Epoch 2 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.286 / Precision : 0.235 / F1 : 0.192\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.28 / Precision : 0.213 / F1 : 0.193\n",
      "\n",
      "########## Epoch 3 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.342 / Precision : 0.259 / F1 : 0.225\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.334 / Precision : 0.257 / F1 : 0.215\n",
      "\n",
      "########## Epoch 4 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.386 / Precision : 0.234 / F1 : 0.255\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.38 / Precision : 0.232 / F1 : 0.25\n",
      "\n",
      "########## Epoch 5 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.424 / Precision : 0.323 / F1 : 0.33\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.406 / Precision : 0.307 / F1 : 0.308\n",
      "\n",
      "########## Epoch 6 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.388 / Precision : 0.234 / F1 : 0.261\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.376 / Precision : 0.221 / F1 : 0.245\n",
      "\n",
      "########## Epoch 7 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.409 / Precision : 0.302 / F1 : 0.305\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.396 / Precision : 0.297 / F1 : 0.29\n",
      "\n",
      "########## Epoch 8 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.418 / Precision : 0.305 / F1 : 0.313\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.406 / Precision : 0.301 / F1 : 0.299\n",
      "\n",
      "########## Epoch 9 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.421 / Precision : 0.309 / F1 : 0.319\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.406 / Precision : 0.298 / F1 : 0.304\n",
      "\n",
      "########## Epoch 10 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.43 / Precision : 0.309 / F1 : 0.325\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.422 / Precision : 0.301 / F1 : 0.316\n",
      "\n",
      "########## Epoch 11 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.436 / Precision : 0.311 / F1 : 0.33\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.426 / Precision : 0.304 / F1 : 0.32\n",
      "\n",
      "########## Epoch 12 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.44 / Precision : 0.315 / F1 : 0.337\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.428 / Precision : 0.307 / F1 : 0.324\n",
      "\n",
      "########## Epoch 13 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.439 / Precision : 0.313 / F1 : 0.334\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.432 / Precision : 0.308 / F1 : 0.325\n",
      "\n",
      "########## Epoch 14 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.442 / Precision : 0.317 / F1 : 0.338\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.444 / Precision : 0.315 / F1 : 0.338\n",
      "\n",
      "########## Epoch 15 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.445 / Precision : 0.323 / F1 : 0.346\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.444 / Precision : 0.317 / F1 : 0.342\n",
      "\n",
      "########## Epoch 16 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.444 / Precision : 0.325 / F1 : 0.348\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.434 / Precision : 0.315 / F1 : 0.339\n",
      "\n",
      "########## Epoch 17 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.451 / Precision : 0.334 / F1 : 0.357\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.45 / Precision : 0.324 / F1 : 0.351\n",
      "\n",
      "########## Epoch 18 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.451 / Precision : 0.343 / F1 : 0.362\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.444 / Precision : 0.335 / F1 : 0.354\n",
      "\n",
      "########## Epoch 19 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.453 / Precision : 0.348 / F1 : 0.365\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.448 / Precision : 0.342 / F1 : 0.359\n",
      "\n",
      "########## Epoch 20 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.453 / Precision : 0.351 / F1 : 0.367\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.452 / Precision : 0.341 / F1 : 0.362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN(0.003, 20, 5, 400, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fdf0d65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Epoch 1 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.526 / Precision : 0.563 / F1 : 0.47\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.508 / Precision : 0.531 / F1 : 0.45\n",
      "\n",
      "########## Epoch 2 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.562 / Precision : 0.587 / F1 : 0.511\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.568 / Precision : 0.547 / F1 : 0.524\n",
      "\n",
      "########## Epoch 3 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.538 / Precision : 0.581 / F1 : 0.465\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.552 / Precision : 0.674 / F1 : 0.486\n",
      "\n",
      "########## Epoch 4 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.559 / Precision : 0.63 / F1 : 0.496\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.57 / Precision : 0.615 / F1 : 0.51\n",
      "\n",
      "########## Epoch 5 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.573 / Precision : 0.675 / F1 : 0.514\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.58 / Precision : 0.607 / F1 : 0.52\n",
      "\n",
      "########## Epoch 6 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.608 / Precision : 0.594 / F1 : 0.553\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.594 / Precision : 0.721 / F1 : 0.543\n",
      "\n",
      "########## Epoch 7 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.651 / Precision : 0.634 / F1 : 0.595\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.632 / Precision : 0.654 / F1 : 0.578\n",
      "\n",
      "########## Epoch 8 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.65 / Precision : 0.567 / F1 : 0.592\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.638 / Precision : 0.567 / F1 : 0.582\n",
      "\n",
      "########## Epoch 9 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.678 / Precision : 0.655 / F1 : 0.629\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.66 / Precision : 0.668 / F1 : 0.615\n",
      "\n",
      "########## Epoch 10 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.683 / Precision : 0.596 / F1 : 0.622\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.668 / Precision : 0.602 / F1 : 0.613\n",
      "\n",
      "########## Epoch 11 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.688 / Precision : 0.602 / F1 : 0.627\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.67 / Precision : 0.61 / F1 : 0.615\n",
      "\n",
      "########## Epoch 12 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.693 / Precision : 0.611 / F1 : 0.634\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.67 / Precision : 0.613 / F1 : 0.617\n",
      "\n",
      "########## Epoch 13 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.697 / Precision : 0.659 / F1 : 0.648\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.678 / Precision : 0.653 / F1 : 0.633\n",
      "\n",
      "########## Epoch 14 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.699 / Precision : 0.614 / F1 : 0.639\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.68 / Precision : 0.618 / F1 : 0.626\n",
      "\n",
      "########## Epoch 15 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.704 / Precision : 0.616 / F1 : 0.643\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.686 / Precision : 0.617 / F1 : 0.63\n",
      "\n",
      "########## Epoch 16 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.704 / Precision : 0.623 / F1 : 0.645\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.692 / Precision : 0.625 / F1 : 0.637\n",
      "\n",
      "########## Epoch 17 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.706 / Precision : 0.622 / F1 : 0.646\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.696 / Precision : 0.626 / F1 : 0.64\n",
      "\n",
      "########## Epoch 18 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.708 / Precision : 0.626 / F1 : 0.65\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.694 / Precision : 0.626 / F1 : 0.639\n",
      "\n",
      "########## Epoch 19 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.706 / Precision : 0.627 / F1 : 0.649\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.69 / Precision : 0.63 / F1 : 0.639\n",
      "\n",
      "########## Epoch 20 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.713 / Precision : 0.629 / F1 : 0.653\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.698 / Precision : 0.628 / F1 : 0.643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN(0.003, 20, 10, 400, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a1c8b9f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Epoch 1 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.63 / Precision : 0.601 / F1 : 0.585\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.604 / Precision : 0.576 / F1 : 0.555\n",
      "\n",
      "########## Epoch 2 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.726 / Precision : 0.758 / F1 : 0.688\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.706 / Precision : 0.664 / F1 : 0.669\n",
      "\n",
      "########## Epoch 3 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.753 / Precision : 0.783 / F1 : 0.728\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.734 / Precision : 0.769 / F1 : 0.712\n",
      "\n",
      "########## Epoch 4 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.787 / Precision : 0.793 / F1 : 0.78\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.776 / Precision : 0.785 / F1 : 0.772\n",
      "\n",
      "########## Epoch 5 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.794 / Precision : 0.802 / F1 : 0.784\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.782 / Precision : 0.792 / F1 : 0.772\n",
      "\n",
      "########## Epoch 6 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.8 / Precision : 0.803 / F1 : 0.797\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.808 / Precision : 0.815 / F1 : 0.806\n",
      "\n",
      "########## Epoch 7 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.807 / Precision : 0.815 / F1 : 0.805\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.81 / Precision : 0.825 / F1 : 0.81\n",
      "\n",
      "########## Epoch 8 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.819 / Precision : 0.824 / F1 : 0.819\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.812 / Precision : 0.822 / F1 : 0.812\n",
      "\n",
      "########## Epoch 9 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.821 / Precision : 0.825 / F1 : 0.82\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.812 / Precision : 0.824 / F1 : 0.812\n",
      "\n",
      "########## Epoch 10 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.827 / Precision : 0.834 / F1 : 0.828\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.804 / Precision : 0.821 / F1 : 0.805\n",
      "\n",
      "########## Epoch 11 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.822 / Precision : 0.829 / F1 : 0.821\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.824 / Precision : 0.84 / F1 : 0.823\n",
      "\n",
      "########## Epoch 12 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.829 / Precision : 0.839 / F1 : 0.83\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.816 / Precision : 0.837 / F1 : 0.817\n",
      "\n",
      "########## Epoch 13 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.835 / Precision : 0.844 / F1 : 0.836\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.818 / Precision : 0.835 / F1 : 0.82\n",
      "\n",
      "########## Epoch 14 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.835 / Precision : 0.843 / F1 : 0.835\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.822 / Precision : 0.835 / F1 : 0.823\n",
      "\n",
      "########## Epoch 15 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.841 / Precision : 0.852 / F1 : 0.842\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.82 / Precision : 0.84 / F1 : 0.821\n",
      "\n",
      "########## Epoch 16 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.841 / Precision : 0.852 / F1 : 0.843\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.82 / Precision : 0.834 / F1 : 0.822\n",
      "\n",
      "########## Epoch 17 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.842 / Precision : 0.853 / F1 : 0.844\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.83 / Precision : 0.856 / F1 : 0.833\n",
      "\n",
      "########## Epoch 18 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.845 / Precision : 0.858 / F1 : 0.847\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.826 / Precision : 0.844 / F1 : 0.828\n",
      "\n",
      "########## Epoch 19 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.842 / Precision : 0.859 / F1 : 0.844\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.818 / Precision : 0.845 / F1 : 0.821\n",
      "\n",
      "########## Epoch 20 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.84 / Precision : 0.857 / F1 : 0.842\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.82 / Precision : 0.848 / F1 : 0.822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN(0.003, 20, 30, 400, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f91fe98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Epoch 1 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.751 / Precision : 0.783 / F1 : 0.735\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.752 / Precision : 0.777 / F1 : 0.732\n",
      "\n",
      "########## Epoch 2 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.787 / Precision : 0.806 / F1 : 0.777\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.774 / Precision : 0.794 / F1 : 0.764\n",
      "\n",
      "########## Epoch 3 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.802 / Precision : 0.82 / F1 : 0.796\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.774 / Precision : 0.797 / F1 : 0.767\n",
      "\n",
      "########## Epoch 4 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.817 / Precision : 0.832 / F1 : 0.813\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.782 / Precision : 0.806 / F1 : 0.778\n",
      "\n",
      "########## Epoch 5 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.819 / Precision : 0.833 / F1 : 0.818\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.796 / Precision : 0.817 / F1 : 0.795\n",
      "\n",
      "########## Epoch 6 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.833 / Precision : 0.846 / F1 : 0.833\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.798 / Precision : 0.826 / F1 : 0.799\n",
      "\n",
      "########## Epoch 7 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.829 / Precision : 0.846 / F1 : 0.829\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.8 / Precision : 0.832 / F1 : 0.8\n",
      "\n",
      "########## Epoch 8 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.836 / Precision : 0.851 / F1 : 0.836\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.808 / Precision : 0.835 / F1 : 0.808\n",
      "\n",
      "########## Epoch 9 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.841 / Precision : 0.854 / F1 : 0.841\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.826 / Precision : 0.852 / F1 : 0.827\n",
      "\n",
      "########## Epoch 10 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.846 / Precision : 0.858 / F1 : 0.847\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.81 / Precision : 0.836 / F1 : 0.812\n",
      "\n",
      "########## Epoch 11 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.836 / Precision : 0.852 / F1 : 0.836\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.808 / Precision : 0.834 / F1 : 0.807\n",
      "\n",
      "########## Epoch 12 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.84 / Precision : 0.854 / F1 : 0.84\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.796 / Precision : 0.824 / F1 : 0.797\n",
      "\n",
      "########## Epoch 13 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.842 / Precision : 0.859 / F1 : 0.841\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.796 / Precision : 0.825 / F1 : 0.795\n",
      "\n",
      "########## Epoch 14 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.843 / Precision : 0.857 / F1 : 0.842\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.8 / Precision : 0.827 / F1 : 0.8\n",
      "\n",
      "########## Epoch 15 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.834 / Precision : 0.851 / F1 : 0.833\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.788 / Precision : 0.817 / F1 : 0.785\n",
      "\n",
      "########## Epoch 16 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.838 / Precision : 0.856 / F1 : 0.838\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.792 / Precision : 0.824 / F1 : 0.79\n",
      "\n",
      "########## Epoch 17 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.85 / Precision : 0.86 / F1 : 0.85\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.802 / Precision : 0.827 / F1 : 0.803\n",
      "\n",
      "########## Epoch 18 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.85 / Precision : 0.863 / F1 : 0.852\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.81 / Precision : 0.841 / F1 : 0.812\n",
      "\n",
      "########## Epoch 19 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.853 / Precision : 0.863 / F1 : 0.853\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.804 / Precision : 0.829 / F1 : 0.804\n",
      "\n",
      "########## Epoch 20 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.855 / Precision : 0.864 / F1 : 0.856\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.82 / Precision : 0.847 / F1 : 0.821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN(0.003, 20, 50, 400, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d84dc453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(learning_rate, epochs, hidden_size1, hidden_size2, n_features, num_labels) :\n",
    "\n",
    "    weights_1 = 0.2 * rng.random((n_features, hidden_size1)) - 0.1\n",
    "    weights_2 = 0.2 * rng.random((hidden_size1, hidden_size2)) - 0.1\n",
    "    weights_3 = 0.2 * rng.random((hidden_size2, num_labels)) - 0.1\n",
    "    \n",
    "    store_training_loss = []\n",
    "    store_test_loss = []\n",
    "\n",
    "    # 훈련 루프 시작\n",
    "    # 정의된 에포크(반복)의 수에 대한 학습 실험을 실행\n",
    "    for j in range(epochs):\n",
    "\n",
    "        #################\n",
    "        #    훈련 단계   #\n",
    "        #################\n",
    "\n",
    "        # 훈련셋의 모든 데이터에 대한 순전파와 역전파를 수행하고 그에 따른 가중치 조정\n",
    "        for i in range(len(X_train)):\n",
    "            layer_0 = X_train[i]\n",
    "            layer_1 = np.dot(layer_0, weights_1)\n",
    "            layer_1 = relu(layer_1)\n",
    "            layer_2 = np.dot(layer_1, weights_2)\n",
    "            layer_2 = relu(layer_2)\n",
    "            dropout_mask = rng.integers(low=0, high=2, size=layer_2.shape)\n",
    "            layer_2 *= dropout_mask * 2\n",
    "            layer_3 = np.dot(layer_2, weights_3)\n",
    "            \n",
    "            # 역전파:\n",
    "        \n",
    "            layer_3_delta = (y_train[i] - layer_3)\n",
    "            layer_2_delta = np.dot(weights_3, layer_3_delta) * relu2deriv(layer_2)\n",
    "            layer_2_delta *= dropout_mask\n",
    "            layer_1_delta = np.dot(weights_2, layer_2_delta) * relu2deriv(layer_1)\n",
    "                                 \n",
    "            weights_1 += learning_rate * np.outer(layer_0, layer_1_delta)\n",
    "            weights_2 += learning_rate * np.outer(layer_1, layer_2_delta)\n",
    "            weights_3 += learning_rate * np.outer(layer_2, layer_3_delta)\n",
    "\n",
    "\n",
    "        ###################\n",
    "        #    측정 단계     #\n",
    "        ###################\n",
    "\n",
    "        train_pred = relu(relu(X_train @ weights_1) @ weights_2) @ weights_3\n",
    "        test_pred = relu(relu(X_test @ weights_1) @ weights_2) @ weights_3\n",
    "\n",
    "\n",
    "        # 세트별 성능측정\n",
    "        tr_recall = round(recall_score(np.argmax(y_train, axis = 1), np.argmax(train_pred, axis = 1), average = 'weighted'), 3)\n",
    "        te_recall = round(recall_score(np.argmax(y_test, axis = 1), np.argmax(test_pred, axis = 1), average = 'weighted'), 3)\n",
    "\n",
    "        tr_precision = round(precision_score(np.argmax(y_train, axis = 1), np.argmax(train_pred, axis = 1), average = 'weighted'), 3)\n",
    "        te_precision = round(precision_score(np.argmax(y_test, axis = 1), np.argmax(test_pred, axis = 1), average = 'weighted'), 3)\n",
    "\n",
    "        tr_f1 = round(f1_score(np.argmax(y_train, axis = 1), np.argmax(train_pred, axis = 1), average = 'weighted'), 3)\n",
    "        te_f1 = round(f1_score(np.argmax(y_test, axis = 1), np.argmax(test_pred, axis = 1), average = 'weighted'), 3)\n",
    "\n",
    "        # 각 에포크에서 성능 출력\n",
    "        print(f'########## Epoch {j + 1} #########')\n",
    "        print(f'Summary of Train Set')\n",
    "        print(f'Recall : {tr_recall} / Precision : {tr_precision} / F1 : {tr_f1}')\n",
    "        print(f'\\nSummary of Test Set')\n",
    "        print(f'Recall : {te_recall} / Precision : {te_precision} / F1 : {te_f1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d01f6ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Epoch 1 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.353 / Precision : 0.337 / F1 : 0.299\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.334 / Precision : 0.31 / F1 : 0.279\n",
      "\n",
      "########## Epoch 2 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.544 / Precision : 0.448 / F1 : 0.483\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.544 / Precision : 0.454 / F1 : 0.485\n",
      "\n",
      "########## Epoch 3 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.524 / Precision : 0.554 / F1 : 0.435\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.498 / Precision : 0.397 / F1 : 0.407\n",
      "\n",
      "########## Epoch 4 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.54 / Precision : 0.53 / F1 : 0.453\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.512 / Precision : 0.496 / F1 : 0.432\n",
      "\n",
      "########## Epoch 5 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.525 / Precision : 0.458 / F1 : 0.46\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.502 / Precision : 0.434 / F1 : 0.44\n",
      "\n",
      "########## Epoch 6 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.555 / Precision : 0.468 / F1 : 0.486\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.542 / Precision : 0.465 / F1 : 0.478\n",
      "\n",
      "########## Epoch 7 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.542 / Precision : 0.484 / F1 : 0.481\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.534 / Precision : 0.486 / F1 : 0.475\n",
      "\n",
      "########## Epoch 8 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.514 / Precision : 0.474 / F1 : 0.458\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.502 / Precision : 0.478 / F1 : 0.454\n",
      "\n",
      "########## Epoch 9 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.474 / Precision : 0.401 / F1 : 0.4\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.45 / Precision : 0.387 / F1 : 0.378\n",
      "\n",
      "########## Epoch 10 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.454 / Precision : 0.383 / F1 : 0.368\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.434 / Precision : 0.38 / F1 : 0.346\n",
      "\n",
      "########## Epoch 11 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.391 / Precision : 0.441 / F1 : 0.33\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.382 / Precision : 0.436 / F1 : 0.32\n",
      "\n",
      "########## Epoch 12 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.286 / Precision : 0.341 / F1 : 0.224\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.272 / Precision : 0.352 / F1 : 0.221\n",
      "\n",
      "########## Epoch 13 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-a4b059e7c946>:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  return (x>=0) * x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Epoch 14 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 15 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 16 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 17 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 18 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 19 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 20 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN(0.003, 20, 50, 10, 400, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06c72d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Epoch 1 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.444 / Precision : 0.554 / F1 : 0.371\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.44 / Precision : 0.347 / F1 : 0.36\n",
      "\n",
      "########## Epoch 2 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.59 / Precision : 0.61 / F1 : 0.544\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.596 / Precision : 0.609 / F1 : 0.544\n",
      "\n",
      "########## Epoch 3 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.616 / Precision : 0.608 / F1 : 0.569\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.642 / Precision : 0.629 / F1 : 0.594\n",
      "\n",
      "########## Epoch 4 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.633 / Precision : 0.627 / F1 : 0.585\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.644 / Precision : 0.639 / F1 : 0.596\n",
      "\n",
      "########## Epoch 5 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.604 / Precision : 0.645 / F1 : 0.552\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.572 / Precision : 0.515 / F1 : 0.521\n",
      "\n",
      "########## Epoch 6 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.513 / Precision : 0.634 / F1 : 0.487\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.492 / Precision : 0.627 / F1 : 0.467\n",
      "\n",
      "########## Epoch 7 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.605 / Precision : 0.584 / F1 : 0.558\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.558 / Precision : 0.569 / F1 : 0.523\n",
      "\n",
      "########## Epoch 8 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.592 / Precision : 0.522 / F1 : 0.535\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.568 / Precision : 0.503 / F1 : 0.514\n",
      "\n",
      "########## Epoch 9 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.492 / Precision : 0.474 / F1 : 0.442\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.458 / Precision : 0.455 / F1 : 0.412\n",
      "\n",
      "########## Epoch 10 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.462 / Precision : 0.466 / F1 : 0.412\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.45 / Precision : 0.463 / F1 : 0.402\n",
      "\n",
      "########## Epoch 11 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.161 / Precision : 0.209 / F1 : 0.098\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.164 / Precision : 0.211 / F1 : 0.106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-a4b059e7c946>:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  return (x>=0) * x\n",
      "<ipython-input-47-fa371d45b95e>:26: RuntimeWarning: invalid value encountered in multiply\n",
      "  layer_2 *= dropout_mask * 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Epoch 12 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 13 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 14 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 15 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 16 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 17 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 18 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 19 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 20 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN(0.003, 20, 40, 20, 400, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bacefe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Epoch 1 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.305 / Precision : 0.267 / F1 : 0.218\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.322 / Precision : 0.268 / F1 : 0.229\n",
      "\n",
      "########## Epoch 2 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.507 / Precision : 0.433 / F1 : 0.431\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.526 / Precision : 0.403 / F1 : 0.443\n",
      "\n",
      "########## Epoch 3 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.502 / Precision : 0.448 / F1 : 0.405\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.516 / Precision : 0.471 / F1 : 0.415\n",
      "\n",
      "########## Epoch 4 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.532 / Precision : 0.473 / F1 : 0.445\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.536 / Precision : 0.482 / F1 : 0.45\n",
      "\n",
      "########## Epoch 5 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.519 / Precision : 0.486 / F1 : 0.43\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.5 / Precision : 0.458 / F1 : 0.408\n",
      "\n",
      "########## Epoch 6 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.51 / Precision : 0.47 / F1 : 0.41\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.502 / Precision : 0.508 / F1 : 0.398\n",
      "\n",
      "########## Epoch 7 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.505 / Precision : 0.446 / F1 : 0.411\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.488 / Precision : 0.466 / F1 : 0.403\n",
      "\n",
      "########## Epoch 8 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.514 / Precision : 0.352 / F1 : 0.398\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.508 / Precision : 0.35 / F1 : 0.393\n",
      "\n",
      "########## Epoch 9 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.508 / Precision : 0.356 / F1 : 0.394\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.5 / Precision : 0.35 / F1 : 0.382\n",
      "\n",
      "########## Epoch 10 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.517 / Precision : 0.364 / F1 : 0.405\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.506 / Precision : 0.353 / F1 : 0.393\n",
      "\n",
      "########## Epoch 11 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.521 / Precision : 0.448 / F1 : 0.42\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.514 / Precision : 0.459 / F1 : 0.414\n",
      "\n",
      "########## Epoch 12 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.493 / Precision : 0.356 / F1 : 0.382\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.49 / Precision : 0.36 / F1 : 0.379\n",
      "\n",
      "########## Epoch 13 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.526 / Precision : 0.394 / F1 : 0.427\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.504 / Precision : 0.378 / F1 : 0.408\n",
      "\n",
      "########## Epoch 14 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.493 / Precision : 0.4 / F1 : 0.408\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.466 / Precision : 0.39 / F1 : 0.387\n",
      "\n",
      "########## Epoch 15 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.47 / Precision : 0.446 / F1 : 0.383\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.466 / Precision : 0.443 / F1 : 0.377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-fa371d45b95e>:33: RuntimeWarning: invalid value encountered in multiply\n",
      "  layer_2_delta *= dropout_mask\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/numeric.py:909: RuntimeWarning: invalid value encountered in multiply\n",
      "  return multiply(a.ravel()[:, newaxis], b.ravel()[newaxis, :], out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Epoch 16 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 17 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 18 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 19 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "########## Epoch 20 #########\n",
      "Summary of Train Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n",
      "Summary of Test Set\n",
      "Recall : 0.1 / Precision : 0.01 / F1 : 0.018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN(0.003, 20, 50, 10, 400, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
