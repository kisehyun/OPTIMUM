{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is [spaCy](https://spacy.io/)?\n",
    "\n",
    "**spaCy** is a free, open-source library for advanced Natural Language Processing (NLP) in Python.\n",
    "\n",
    "spaCy provides a variety of linguistic annotations to give you **insights in to text's grammatical structure.** This includes the word types, like the parts of speech, and how the words are related to each other.\n",
    "\n",
    "![spacy](figures/spacy_logo.png \"NLTK\")\n",
    "\n",
    "Similar to NLTK, spaCy provides a range of features and capabilities related to linguistic concepts and even more general machine learning functionalities.\n",
    "\n",
    "Here is the list of things spaCy allows you to do (you can also visualize them using spaCy's built-in function, **displaCy**.\n",
    "\n",
    "\n",
    "| NAME\t| DESCRIPTION |\n",
    "| :------------- | :----------: |\n",
    "**Tokenization** | Segmenting text into words, punctuations marks etc.\n",
    "**Part-of-speech (POS) Tagging**\t | Assigning word types to tokens, like verb or noun.\n",
    "**Dependency Parsing**\t | Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.\n",
    "**Lemmatization**\t | Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”.\n",
    "**Sentence Boundary Detection (SBD)** | \tFinding and segmenting individual sentences.\n",
    "**Named Entity Recognition (NER)**\t | Labelling named “real-world” objects, like persons, companies or locations.\n",
    "**Entity Linking (EL)** | \tDisambiguating textual entities to unique identifiers in a knowledge base.\n",
    "**Similarity**\t | Comparing words, text spans and documents and how similar they are to each other.\n",
    "**Text Classification**\t | Assigning categories or labels to a whole document, or parts of a document.\n",
    "**Rule-based Matching**\t | Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.\n",
    "**Training**\t | Updating and improving a statistical model’s predictions.\n",
    "**Serialization**\t | Saving objects to files or byte strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T04:12:16.179566Z",
     "start_time": "2021-07-02T04:12:16.175323Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "If you do not have spacy and its english package installed, un-comment the following two lines and make sure you install them.\n",
    "'''\n",
    "\n",
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1. Word Tokenization\n",
    "This section uses a trained pipline (i.e., `en_core_web_sm`) to create a `Language` object containing all the components and data needed to process text.\n",
    "\n",
    "The `Language` object will enable you to lemmatize, apply POS tags, dependency parse and even figure out the shape of the tokens present in the given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:55:57.405116Z",
     "start_time": "2021-07-02T07:55:54.560840Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the `Language` object\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:55:57.417926Z",
     "start_time": "2021-07-02T07:55:57.406684Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple     PROPN  nsubj\n",
      "is        AUX    aux\n",
      "looking   VERB   ROOT\n",
      "at        ADP    prep\n",
      "buying    VERB   pcomp\n",
      "U.K.      PROPN  compound\n",
      "startup   NOUN   dobj\n",
      "for       ADP    prep\n",
      "$         SYM    quantmod\n",
      "1         NUM    compound\n",
      "billion   NUM    pobj\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(\"{:<10}{:<7}{}\".format(token.text, token.pos_, token.dep_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:55:57.572377Z",
     "start_time": "2021-07-02T07:55:57.419344Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The       DET    det\n",
      "first     ADJ    amod\n",
      "Tesla     PROPN  compound\n",
      "Model     PROPN  compound\n",
      "S         PROPN  compound\n",
      "Plaid     PROPN  compound\n",
      "models    NOUN   nsubj\n",
      "are       AUX    ROOT\n",
      "about     ADJ    acomp\n",
      "to        PART   aux\n",
      "be        AUX    auxpass\n",
      "delivered VERB   xcomp\n",
      "to        ADP    prep\n",
      "customers NOUN   pobj\n",
      "on        ADP    prep\n",
      "June      PROPN  compound\n",
      "10th      NOUN   pobj\n",
      ",         PUNCT  punct\n",
      "            SPACE  \n",
      "but       CCONJ  cc\n",
      "CEO       PROPN  compound\n",
      "Elon      PROPN  compound\n",
      "Musk      PROPN  nsubj\n",
      "has       AUX    aux\n",
      "just      ADV    advmod\n",
      "announced VERB   ROOT\n",
      "that      SCONJ  mark\n",
      "the       DET    det\n",
      "range     NOUN   npadvmod\n",
      "-         PUNCT  punct\n",
      "topping   VERB   ccomp\n",
      "1,100hp   NUM    punct\n",
      "Plaid+    PROPN  punct\n",
      "variant   NOUN   nsubjpass\n",
      "will      VERB   aux\n",
      "no        ADV    neg\n",
      "longer    ADV    advmod\n",
      "be        AUX    auxpass\n",
      "offered   VERB   ROOT\n",
      ".         PUNCT  punct\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The first Tesla Model S Plaid models are about to be delivered to customers on June 10th, \\\n",
    "            but CEO Elon Musk has just announced that the range-topping 1,100hp Plaid+ variant will no longer be offered.\")\n",
    "for token in doc:\n",
    "    print(\"{:<10}{:<7}{}\".format(token.text, token.pos_, token.dep_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `nlp` object on a string of text will return a processed `Doc` object. You can think of `Doc` (denoted as the object name `doc` here) as a container for accessing linguistic annotations.\n",
    "\n",
    "Take a look at these `Doc` attributes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:55:57.654013Z",
     "start_time": "2021-07-02T07:55:57.574483Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '_bulk_merge', '_py_tokens', '_realloc', '_vector', '_vector_norm', 'cats', 'char_span', 'count_by', 'doc', 'ents', 'extend_tensor', 'from_array', 'from_bytes', 'from_disk', 'get_extension', 'get_lca_matrix', 'has_extension', 'has_vector', 'is_nered', 'is_parsed', 'is_sentenced', 'is_tagged', 'lang', 'lang_', 'mem', 'merge', 'noun_chunks', 'noun_chunks_iterator', 'print_tree', 'remove_extension', 'retokenize', 'sentiment', 'sents', 'set_extension', 'similarity', 'tensor', 'text', 'text_with_ws', 'to_array', 'to_bytes', 'to_disk', 'to_json', 'to_utf8_array', 'user_data', 'user_hooks', 'user_span_hooks', 'user_token_hooks', 'vector', 'vector_norm', 'vocab']\n"
     ]
    }
   ],
   "source": [
    "print(dir(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "During the above process, spaCy tokenizes the text as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:55:57.813962Z",
     "start_time": "2021-07-02T07:55:57.656767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple  /  is  /  looking  /  at  /  buying  /  U.K.  /  startup  /  for  /  $  /  1  /  billion  /  "
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, end=\"  /  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the raw text is split on whitespace characters, similar to `text.split(' ')`. Then, the tokenizer processes the text from left to right. On each substring, it performs two checks:\n",
    "\n",
    "1. Does the substring match a tokenizer exception rule? For example, **“don’t”** does not contain whitespace, but should be split into two tokens, **“do”** and **“n’t”**, while **“U.K.”** should always remain one token.\n",
    "\n",
    "2. Can a prefix, suffix or infix be split off? For example punctuation like commas, periods, hyphens or quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:55:57.952432Z",
     "start_time": "2021-07-02T07:55:57.819003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do  /  n't  /  do  /  that  /  ,  /  John  /  .  /  You  /  're  /  intimidating  /  him  /  .  /  Let  /  's  /  go  /  .  /  "
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Don't do that, John. You're intimidating him. Let's go.\")\n",
    "for token in doc:\n",
    "    print(token.text,end=\"  /  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-speech (POS) tags and dependencies\n",
    "The trained pipelines and statistical models within spaCy enable it to **make predictions** of which tag or label most likely applies in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:55:58.060537Z",
     "start_time": "2021-07-02T07:55:57.957996Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:56:07.549443Z",
     "start_time": "2021-07-02T07:55:58.067491Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple               Apple          PROPN     NNP       nsubj     Xxxxx     1         False\n",
      "is                  be             AUX       VBZ       aux       xx        1         True\n",
      "looking             look           VERB      VBG       ROOT      xxxx      1         False\n",
      "at                  at             ADP       IN        prep      xx        1         True\n",
      "buying              buy            VERB      VBG       pcomp     xxxx      1         False\n",
      "U.K.                U.K.           PROPN     NNP       compound  X.X.      0         False\n",
      "startup             startup        NOUN      NN        dobj      xxxx      1         False\n",
      "for                 for            ADP       IN        prep      xxx       1         True\n",
      "$                   $              SYM       $         quantmod  $         0         False\n",
      "1                   1              NUM       CD        compound  d         0         False\n",
      "billion             billion        NUM       CD        pobj      xxxx      1         False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kisehyun/opt/anaconda3/lib/python3.8/site-packages/spacy/displacy/__init__.py:94: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"803354fd155c45e3af084f9d18ccd694-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">billion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-803354fd155c45e3af084f9d18ccd694-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-803354fd155c45e3af084f9d18ccd694-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-803354fd155c45e3af084f9d18ccd694-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-803354fd155c45e3af084f9d18ccd694-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-803354fd155c45e3af084f9d18ccd694-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-803354fd155c45e3af084f9d18ccd694-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-803354fd155c45e3af084f9d18ccd694-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-803354fd155c45e3af084f9d18ccd694-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-803354fd155c45e3af084f9d18ccd694-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-803354fd155c45e3af084f9d18ccd694-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-803354fd155c45e3af084f9d18ccd694-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-803354fd155c45e3af084f9d18ccd694-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-803354fd155c45e3af084f9d18ccd694-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-803354fd155c45e3af084f9d18ccd694-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-803354fd155c45e3af084f9d18ccd694-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-803354fd155c45e3af084f9d18ccd694-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-803354fd155c45e3af084f9d18ccd694-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-803354fd155c45e3af084f9d18ccd694-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-803354fd155c45e3af084f9d18ccd694-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-803354fd155c45e3af084f9d18ccd694-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(\"{:<20}{:<15}{:<10}{:<10}{:<10}{:<10}{:<10}{}\".format(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop))\n",
    "\n",
    "# Call `displacy.serve` for dependency visualization\n",
    "displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:56:07.564614Z",
     "start_time": "2021-07-02T07:56:07.553807Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do                  do             AUX       VB        aux       Xx        1         True\n",
      "n't                 not            PART      RB        neg       x'x       0         True\n",
      "do                  do             AUX       VB        ROOT      xx        1         True\n",
      "that                that           DET       DT        dobj      xxxx      1         True\n",
      ",                   ,              PUNCT     ,         punct     ,         0         False\n",
      "John                John           PROPN     NNP       npadvmod  Xxxx      1         False\n",
      ".                   .              PUNCT     .         punct     .         0         False\n",
      "You                 -PRON-         PRON      PRP       nsubj     Xxx       1         True\n",
      "'re                 be             AUX       VBP       aux       'xx       0         True\n",
      "intimidating        intimidate     VERB      VBG       ROOT      xxxx      1         False\n",
      "him                 -PRON-         PRON      PRP       dobj      xxx       1         True\n",
      ".                   .              PUNCT     .         punct     .         0         False\n",
      "Let                 let            VERB      VB        ROOT      Xxx       1         False\n",
      "'s                  -PRON-         PRON      PRP       nsubj     'x        0         True\n",
      "go                  go             VERB      VB        ccomp     xx        1         True\n",
      ".                   .              PUNCT     .         punct     .         0         False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Don't do that, John. You're intimidating him. Let's go.\")\n",
    "for token in doc:\n",
    "    print(\"{:<20}{:<15}{:<10}{:<10}{:<10}{:<10}{:<10}{}\".format(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)\n",
    "\n",
    "A named entity is a “real-world object” that’s assigned a name – for example, a person, a country, a product or a book title. spaCy can **recognize various types of named entities in a document, by asking the model for a prediction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:56:13.459121Z",
     "start_time": "2021-07-02T07:56:07.565834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:56:19.417920Z",
     "start_time": "2021-07-02T07:56:15.472283Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 4 9 ORDINAL\n",
      "Model S Plaid 16 29 ORG\n",
      "June 10th 79 88 DATE\n",
      "Elon Musk 110 119 ORG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " Tesla \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Model S Plaid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " models are about to be delivered to customers on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    June 10th\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ",             but CEO \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Elon Musk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has just announced that the range-topping 1,100hp Plaid+ variant will no longer be offered.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The first Tesla Model S Plaid models are about to be delivered to customers on June 10th, \\\n",
    "            but CEO Elon Musk has just announced that the range-topping 1,100hp Plaid+ variant will no longer be offered.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Quick Tip) BIO Tagging (a.k.a IOB schema)\n",
    "\n",
    "How does an NER model work?\n",
    "\n",
    "An NER model typically uses the BIO schema, which tags the beginning of a name entity token as **\"B\"** and the intermediate and last tokens as **\"I\"**.\n",
    "\n",
    "![bio](figures/bio_tagging.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T08:45:22.011781Z",
     "start_time": "2021-07-02T08:45:21.993149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('San Francisco', 0, 13, 'GPE')]\n",
      "San        / B  / GPE \n",
      "Francisco  / I  / GPE \n",
      "considers  / O  /  \n",
      "banning    / O  /  \n",
      "sidewalk   / O  /  \n",
      "delivery   / O  /  \n",
      "robots     / O  /  \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"San Francisco considers banning sidewalk delivery robots\")\n",
    "\n",
    "# document level\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print(ents)\n",
    "\n",
    "# token level\n",
    "for word in doc:\n",
    "    print(\"{:<10} / {:<2} / {} \".format(word.text, word.ent_iob_, word.ent_type_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T08:45:22.214276Z",
     "start_time": "2021-07-02T08:45:22.193195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('U.S.', 7, 11, 'GPE'), ('328 million', 13, 24, 'CARDINAL'), ('the last week', 58, 71, 'DATE'), ('1.12 million', 87, 99, 'CARDINAL')]\n",
      "In         / O  /  \n",
      "the        / O  /  \n",
      "U.S.       / B  / GPE \n",
      ",          / O  /  \n",
      "328        / B  / CARDINAL \n",
      "million    / I  / CARDINAL \n",
      "doses      / O  /  \n",
      "have       / O  /  \n",
      "been       / O  /  \n",
      "given      / O  /  \n",
      "so         / O  /  \n",
      "far        / O  /  \n",
      ".          / O  /  \n",
      "In         / O  /  \n",
      "the        / B  / DATE \n",
      "last       / I  / DATE \n",
      "week       / I  / DATE \n",
      ",          / O  /  \n",
      "an         / O  /  \n",
      "average    / O  /  \n",
      "of         / O  /  \n",
      "1.12       / B  / CARDINAL \n",
      "million    / I  / CARDINAL \n",
      "doses      / O  /  \n",
      "per        / O  /  \n",
      "day        / O  /  \n",
      "             / O  /  \n",
      "were       / O  /  \n",
      "administered / O  /  \n",
      ".          / O  /  \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"In the U.S., 328 million doses have been given so far. In the last week, an average of 1.12 million doses per day \\\n",
    "            were administered.\")\n",
    "\n",
    "# document level\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print(ents)\n",
    "\n",
    "# token level\n",
    "for word in doc:\n",
    "    print(\"{:<10} / {:<2} / {} \".format(word.text, word.ent_iob_, word.ent_type_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors and similarity\n",
    "**Similarity** of two words is determined by comparing two word vectors or **\"word embeddings\"**.\n",
    "\n",
    "> A **word embedding** is a multi-dimensional meaning representations of a word.\n",
    "\n",
    "> Word vectors can be generated using an algorithm like **word2vec**.\n",
    "\n",
    "Here, we'll be using `en_core_web_lg`, since `en_core_web_sm` we've been using so far does not contain the token-level word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:56:41.789499Z",
     "start_time": "2021-07-02T07:56:21.285964Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check if a token has a vector assigned, and get the L2-norm, which can be used to normalize vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T08:09:46.675332Z",
     "start_time": "2021-07-02T08:09:43.013649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog       1      7.0340                                                                                                   \n",
      "cat       1      6.6810                                                                                                   \n",
      "banana    1      6.7000                                                                                                   \n",
      "afskfsd   0      0.0001                                                                                                   \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "tokens = nlp(\"dog cat banana afskfsd\")\n",
    "\n",
    "for token in tokens:\n",
    "    print(\"{:<10}{:<7}{:.3f}{:<100}\".format(token.text, token.has_vector, token.vector_norm, token.is_oov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity between Documents, Spans and Words\n",
    "\n",
    "Pipeline packages that come with built-in word vectors make them available as the **`Token.vector`** attribute.\n",
    "\n",
    "**`Doc.vector`** and **`Span.vector`** will default to an average of their token vectors. \n",
    "\n",
    "Using these vectors, you can compare two objects and make a prediction of **how similar they are.** This is very useful in building recommendation systems or flagging duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T08:20:53.519517Z",
     "start_time": "2021-07-02T08:20:53.472489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers. <-> Fast food tastes very good. :\n",
      "[ Similarity : 0.7687607012190486]\n",
      "\n",
      "salty fries <-> hamburgers :\n",
      "[ Similarity : 0.6949787735939026]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")\n",
    "\n",
    "# Similarity of two documents\n",
    "print(\"{} <-> {} :\\n[ Similarity : {}]\\n\".format(doc1, doc2, doc1.similarity(doc2)))\n",
    "\n",
    "# Similarity of tokens and spans\n",
    "french_fries = doc1[2:4]\n",
    "burgers = doc1[5]\n",
    "print(\"{} <-> {} :\\n[ Similarity : {}]\\n\".format(french_fries, burgers, french_fries.similarity(burgers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T08:21:04.889586Z",
     "start_time": "2021-07-02T08:21:04.871225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyundai is a company that employs cutting-edge technology to build cars. <-> Tesla is a car manufacturer that builds electric cars. :\n",
      "[ Similarity : 0.8532010418873383]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"Hyundai is a company that employs cutting-edge technology to build cars.\")\n",
    "doc2 = nlp(\"Tesla is a car manufacturer that builds electric cars.\")\n",
    "\n",
    "print(\"{} <-> {} :\\n[ Similarity : {}]\\n\".format(doc1, doc2, doc1.similarity(doc2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T08:23:44.942563Z",
     "start_time": "2021-07-02T08:23:44.903751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love trees. <-> I hate trees. :\n",
      "[ Similarity : 0.9551339940261838]\n",
      "\n",
      "love <-> hate :\n",
      "[ Similarity : 0.6393099037154144]\n",
      "\n",
      "tree <-> tree :\n",
      "[ Similarity : 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"I love trees.\")\n",
    "doc2 = nlp(\"I hate trees.\")\n",
    "\n",
    "print(\"{} <-> {} :\\n[ Similarity : {}]\\n\".format(doc1, doc2, doc1.similarity(doc2)))\n",
    "\n",
    "word1 = nlp(\"love\")\n",
    "word2 = nlp(\"hate\")\n",
    "print(\"{} <-> {} :\\n[ Similarity : {}]\\n\".format(word1, word2, word1.similarity(word2)))\n",
    "\n",
    "word3 = nlp(\"tree\")\n",
    "word4 = nlp(\"tree\")\n",
    "print(\"{} <-> {} :\\n[ Similarity : {}]\\n\".format(word3, word4, word3.similarity(word4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "1. **spaCy**\n",
    "    - (1.1) Apply POS tagging and extract all the proper nouns (PROPN) and numbers (NUM) from the given text.\n",
    "    - (1.2) Apply NER and extract all the numbers from the given text, along with their type (e.g., MONEY, CARDINAL, etc.)\n",
    "    - (1.3) For the given set of documents, compare: (i) Document-wise similarity, (ii) Span-wise similarity, and (iii) Word-level similarity\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Apply POS tagging and extract all the proper nouns (PROPN) and numbers (NUM) from the given text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Advanced Micro had unveiled the deal in October last year as part of its battle to overtake chipmaking rival Intel Corp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Advanced Micro had unveiled the deal in October last year as part of its battle to overtake chipmaking rival Intel Corp.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Advanced Micro had unveiled the deal in October last year as part of its battle to overtake chipmaking rival Intel Corp.'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "num_list = []\n",
    "propn_list = []\n",
    "\n",
    "for token in doc :\n",
    "    \n",
    "    t = token.text\n",
    "    pos = token.pos_\n",
    "    \n",
    "    if pos == 'PROPN' :\n",
    "        propn_list.append(t)\n",
    "    elif pos == 'NUM' :\n",
    "        num_list.append(t)\n",
    "    else :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Advanced', 'Micro', 'October', 'Intel', 'Corp.']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Just like most of big tech, Nvidia topped in early September, hitting roughly \\$588 a share. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Just like most of big tech, Nvidia topped in early September, hitting roughly $588 a share.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Just like most of big tech, Nvidia topped in early September, hitting roughly $588 a share.'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "num_list = []\n",
    "propn_list = []\n",
    "for token in doc:\n",
    "    t = token.text\n",
    "    pos = token.pos_\n",
    "    if pos == 'PROPN' :\n",
    "        propn_list.append(t)\n",
    "    elif pos == 'NUM' :\n",
    "        num_list.append(t)\n",
    "    else :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nvidia', 'September']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['588']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Most analysts assumed a net increase of 7 to 10% from the starting price of 712 dollars per share. Nevertheless, the stock went through the roof when it shattered the 800 dollar cap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Most analysts assumed a net increase of 7 to 10% from the starting price of 712 dollars per share. Nevertheless, the stock went through the roof when it shattered the 800 dollar cap.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Most analysts assumed a net increase of 7 to 10% from the starting price of 712 dollars per share. Nevertheless, the stock went through the roof when it shattered the 800 dollar cap.'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "num_list = []\n",
    "propn_list = []\n",
    "for token in doc:\n",
    "    t = token.text\n",
    "    pos = token.pos_\n",
    "    if pos == 'PROPN' :\n",
    "        propn_list.append(t)\n",
    "    elif pos == 'NUM' :\n",
    "        num_list.append(t)\n",
    "    else :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7', '10', '712', '800']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Apply NER and extract all the numbers from the given text, along with their type (e.g., MONEY, CARDINAL, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Of 263,000 Amazon factory workers, just over 88,000 (33.6%) had received their first shot and about 43,000 (16.3%) had received both doses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Of 263,000 Amazon factory workers, just over 88,000 (33.6%) had received their first shot and about 43,000 (16.3%) had received both doses.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263,000 3 10 CARDINAL\n",
      "Amazon 11 17 ORG\n",
      "just over 88,000 35 51 CARDINAL\n",
      "33.6% 53 58 PERCENT\n",
      "first 79 84 ORDINAL\n",
      "about 43,000 94 106 CARDINAL\n",
      "16.3% 108 113 PERCENT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    263,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " factory workers, \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    just over 88,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    33.6%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       ") had received their \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " shot and \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    about 43,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    16.3%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       ") had received both doses.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To support vaccination access for the sector, the federal government announced 13 clinics in multiple locations for aged-care staff and that they will be providing supplementary vaccines until the end of December."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('To support vaccination access for the sector, the federal government announced 13 clinics in multiple locations for aged-care staff and that they will be providing supplementary vaccines until the end of December.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 79 81 CARDINAL\n",
      "the end of December 193 212 DATE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">To support vaccination access for the sector, the federal government announced \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    13\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " clinics in multiple locations for aged-care staff and that they will be providing supplementary vaccines until \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the end of December\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The decision reflects a greater understanding of the real, but extremely low, risk of the clotting disorder called thrombosis with thrombocytopenia (TTS) for people aged 50-59, who are now recommended to have the Pfizer vaccine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(' The decision reflects a greater understanding of the real, but extremely low, risk of the clotting disorder called thrombosis with thrombocytopenia (TTS) for people aged 50-59, who are now recommended to have the Pfizer vaccine.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTS 150 153 ORG\n",
      "50-59 171 176 DATE\n",
      "Pfizer 214 220 ORG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The decision reflects a greater understanding of the real, but extremely low, risk of the clotting disorder called thrombosis with thrombocytopenia (\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    TTS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ") for people aged \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    50-59\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", who are now recommended to have the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pfizer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " vaccine.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) For the given set of documents, compare: \n",
    "    (i) Document-wise similarity\n",
    "    (ii) Span-wise similarity\n",
    "    (iii) Word-level similarity\n",
    "\n",
    "**Make sure to extract the \"spans\" and \"words\" straight from the document. Do NOT just write the words (e.g., doc = nlp(\"pop rock\")) and compute the similarity. They must be extracted from the document (e.g., doc = nlp(document[14:20]))**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "**[ Document 1 ]**\n",
    "\n",
    "AC/DC are an Australian rock band formed in Sydney in 1973 by Scottish-born brothers Malcolm and Angus Young. Their music has been variously described as hard rock, blues rock, and heavy metal,but the band themselves call it simply \"rock and roll\".\n",
    "\n",
    "**[ Document 2 ]**\n",
    "\n",
    "Queen are a British rock band formed in London in 1970. Their classic line-up was Freddie Mercury (lead vocals, piano), Brian May (guitar, vocals), Roger Taylor (drums, vocals) and John Deacon (bass). Their earliest works were influenced by progressive rock, hard rock and heavy metal, but the band gradually ventured into more conventional and radio-friendly works by incorporating further styles, such as arena rock and pop rock.\n",
    "\n",
    "**[ Spans ]**\n",
    "\n",
    "\"Their music has been variously described as hard rock\" **<->** \"Queen are a British rock band formed in London in 1970\"\n",
    "\n",
    "\"Their music has been variously described as hard rock, blues rock, and heavy metal\" **<->** \"Their earliest works were influenced by progressive rock, hard rock and heavy metal\"\n",
    "\n",
    "**[ Words ]**\n",
    "\n",
    "\"pop rock\" **<->** \"heavy metal\"\n",
    "\n",
    "\"pop rock\" **<->** \"hard rock\"\n",
    "\n",
    "\"Austrailian\" **<->** \"British\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-wise similarity : 0.9581961723629089\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp('AC/DC are an Australian rock band formed in Sydney in 1973 by Scottish-born brothers Malcolm and Angus Young. Their music has been variously described as hard rock, blues rock, and heavy metal,but the band themselves call it simply \"rock and roll\".')\n",
    "doc2 = nlp('Queen are a British rock band formed in London in 1970. Their classic line-up was Freddie Mercury (lead vocals, piano), Brian May (guitar, vocals), Roger Taylor (drums, vocals) and John Deacon (bass). Their earliest works were influenced by progressive rock, hard rock and heavy metal, but the band gradually ventured into more conventional and radio-friendly works by incorporating further styles, such as arena rock and pop rock.')\n",
    "\n",
    "print(f\"Document-wise similarity : {doc1.similarity(doc2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span-wise similarity : 0.721413254737854\n"
     ]
    }
   ],
   "source": [
    "span1 = doc1[23:31]\n",
    "span2 = doc2[:11]\n",
    "\n",
    "print(f\"Span-wise similarity : {span1.similarity(span2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span-wise similarity : 0.952633798122406\n"
     ]
    }
   ],
   "source": [
    "span3 = doc1[23:39]\n",
    "span4 = doc2[49:63]\n",
    "\n",
    "print(f\"Span-wise similarity : {span3.similarity(span4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-level similarity heavy metal & pop rock : 0.5599331855773926\n"
     ]
    }
   ],
   "source": [
    "word1 = doc1[37:39]\n",
    "word2 = doc2[-3:-1]\n",
    "\n",
    "print(f\"Word-level similarity {word1} & {word2} : {word1.similarity(word2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-level similarity hard rock & pop rock : 0.8158590197563171\n"
     ]
    }
   ],
   "source": [
    "word1 = doc1[30:32]\n",
    "word2 = doc2[-3:-1]\n",
    "\n",
    "print(f\"Word-level similarity {word1} & {word2} : {word1.similarity(word2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-level similarity Australian & British : 0.7410552501678467\n"
     ]
    }
   ],
   "source": [
    "word1 = doc1[5]\n",
    "word2 = doc2[3]\n",
    "\n",
    "print(f\"Word-level similarity {word1} & {word2} : {word1.similarity(word2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:19:54.770699Z",
     "start_time": "2021-07-02T09:19:54.762624Z"
    }
   },
   "source": [
    "2.\n",
    "\n",
    "**[ Document 1 ]**\n",
    "\n",
    "Tesla, Inc. is an American electric vehicle and clean energy company based in Palo Alto, California. Tesla's current products include electric cars, battery energy storage from home to grid-scale, solar panels and solar roof tiles, as well as other related products and services. In 2020, Tesla had the highest sales in the plug-in and battery electric passenger car segments, capturing 16% of the plug-in market (which includes plug-in hybrids) and 23% of the battery-electric (purely electric) market. Through its subsidiary Tesla Energy, the company develops and is a major installer of solar photovoltaic energy generation systems in the United States. Tesla Energy is also one of the largest global suppliers of battery energy storage systems, with 3 GWh of battery storage supplied in 2020.\n",
    "\n",
    "**[ Document 2 ]**\n",
    "\n",
    "Apple Inc. is an American multinational technology company that specializes in consumer electronics, computer software, and online services. Apple is the world's largest technology company by revenue (totalling $274.5 billion in 2020) and, since January 2021, the world's most valuable company. As of 2021, Apple is the world's fourth-largest PC vendor by unit sales,[9] and fourth-largest smartphone manufacturer. It is one of the Big Five American information technology companies, along with Amazon, Google, Microsoft, and Facebook\n",
    "\n",
    "**[ Spans ]**\n",
    "\n",
    "\"American electric vehicle and clean energy company based in Palo Alto, California\" **<->** \"American multinational technology company\"\n",
    "\n",
    "\"Tesla's current products include electric cars, battery energy storage from home to grid-scale\" **<->** \"Apple is the world's largest technology company by revenue\"\n",
    "\n",
    "**[ Words ]**\n",
    "\n",
    "\"solar panels\" **<->** \"smartphone\"\n",
    "\n",
    "\"highest sales\" **<->** \"multinational\"\n",
    "\n",
    "\"United States\" **<->** \"Amazon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-wise similarity : 0.9161351077425979\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"Tesla, Inc. is an American electric vehicle and clean energy company based in Palo Alto, California. Tesla's current products include electric cars, battery energy storage from home to grid-scale, solar panels and solar roof tiles, as well as other related products and services. In 2020, Tesla had the highest sales in the plug-in and battery electric passenger car segments, capturing 16% of the plug-in market (which includes plug-in hybrids) and 23% of the battery-electric (purely electric) market. Through its subsidiary Tesla Energy, the company develops and is a major installer of solar photovoltaic energy generation systems in the United States. Tesla Energy is also one of the largest global suppliers of battery energy storage systems, with 3 GWh of battery storage supplied in 2020.\")\n",
    "doc2 = nlp(\"Apple Inc. is an American multinational technology company that specializes in consumer electronics, computer software, and online services. Apple is the world's largest technology company by revenue (totalling $274.5 billion in 2020) and, since January 2021, the world's most valuable company. As of 2021, Apple is the world's fourth-largest PC vendor by unit sales,[9] and fourth-largest smartphone manufacturer. It is one of the Big Five American information technology companies, along with Amazon, Google, Microsoft, and Facebook.\")\n",
    "\n",
    "print(f\"Document-wise similarity : {doc1.similarity(doc2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span-wise similarity : 0.6886041760444641\n"
     ]
    }
   ],
   "source": [
    "span1 = doc1[5:18]\n",
    "span2 = doc2[4:8]\n",
    "\n",
    "print(f\"Span-wise similarity : {span1.similarity(span2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span-wise similarity : 0.735293984413147\n"
     ]
    }
   ],
   "source": [
    "span3 = doc1[19:36]\n",
    "span4 = doc2[21:31]\n",
    "\n",
    "print(f\"Span-wise similarity : {span3.similarity(span4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-level similarity solar panels & smartphone : 0.21279482543468475\n"
     ]
    }
   ],
   "source": [
    "word1 = doc1[37:39]\n",
    "word2 = doc2[74]\n",
    "\n",
    "print(f\"Word-level similarity {word1} & {word2} : {word1.similarity(word2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-level similarity highest sales & multinational : 0.28202834725379944\n"
     ]
    }
   ],
   "source": [
    "word3 = doc1[59:61]\n",
    "word4 = doc2[5]\n",
    "\n",
    "print(f\"Word-level similarity {word3} & {word4} : {word3.similarity(word4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-level similarity United States & Amazon : 0.21113549172878265\n"
     ]
    }
   ],
   "source": [
    "word5 = doc1[126:128]\n",
    "word6 = doc2[-9]\n",
    "\n",
    "print(f\"Word-level similarity {word5} & {word6} : {word5.similarity(word6)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
